{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fde26f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4523/2858291554.py:24: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "\n",
    "file_path = \"wine_quality_classification.csv\"\n",
    "\n",
    "\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"sahideseker/wine-quality-classification\",\n",
    "  file_path,\n",
    "  \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2f89a",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "059aa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_order = [\"low\", \"medium\", \"high\"]  \n",
    "encoder = OrdinalEncoder(\n",
    "    categories=[quality_order],\n",
    "    handle_unknown='use_encoded_value',  \n",
    "    unknown_value=-1  \n",
    ")\n",
    "y_encoded = encoder.fit_transform(df[['quality_label']]).ravel()\n",
    "\n",
    "\n",
    "X = df.drop(columns=\"quality_label\")\n",
    "y = y_encoded\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b901538",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "158033eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_lr = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 10000,\n",
    "    \"random_state\": 8888,\n",
    "\n",
    "    \"class_weight\": \"balanced\",  \n",
    "    \"penalty\": \"l2\",\n",
    "    \"C\": 0.1  \n",
    "}\n",
    "\n",
    "lr = LogisticRegression(**params_lr)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "\n",
    "\n",
    "y_proba = lr.predict_proba(X_test)\n",
    "report_dict_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "702f534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_rf = {\n",
    "    \"n_estimators\": 30,\n",
    "    \"max_depth\": 3\n",
    "}\n",
    "rf_clf = RandomForestClassifier(**params_rf)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "report_dict_rf = classification_report(y_test, y_pred_rf, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7cc60",
   "metadata": {},
   "source": [
    "# MLflow structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a8c9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"LogisticRegression\": lr, \"RandomForest\": rf_clf}\n",
    "params = {\"LogisticRegression\": params_lr, \"RandomForest\": params_rf}\n",
    "report_dict = {\"LogisticRegression\": report_dict_lr, \"RandomForest\": report_dict_rf}\n",
    "wine_feature_names = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5995ba",
   "metadata": {},
   "source": [
    "## Single Experiment with multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1612c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/29 14:33:25 INFO mlflow.tracking.fluent: Experiment with name 'MLflow Wine' does not exist. Creating a new experiment.\n",
      "Successfully registered model 'tracking-wine'.\n",
      "2025/04/29 14:33:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: tracking-wine, version 1\n",
      "Created version '1' of model 'tracking-wine'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run inquisitive-fowl-377 at: http://127.0.0.1:5000/#/experiments/340645493566817619/runs/044b07dee4cd4ad59cc194b31d592b07\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/340645493566817619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.43it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>density</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>4.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>15.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>12.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>6.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1.0043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed_acidity  residual_sugar  alcohol  density  actual_class  \\\n",
       "136            4.8             8.9     12.1   0.9961           1.0   \n",
       "755           15.3            14.2     13.0   1.0025           0.0   \n",
       "239           12.7            10.4     10.3   0.9957           1.0   \n",
       "522            6.3             6.6     12.5   1.0043           1.0   \n",
       "\n",
       "     predicted_class  \n",
       "136              0.0  \n",
       "755              0.0  \n",
       "239              1.0  \n",
       "522              0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"MLflow Wine\")\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_params(params[model_name])\n",
    "        \n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": report_dict[model_name][\"accuracy\"],\n",
    "            \"recall_class_0\": report_dict[model_name][\"0.0\"][\"recall\"],\n",
    "            \"recall_class_1\": report_dict[model_name][\"1.0\"][\"recall\"],\n",
    "            \"recall_class_2\": report_dict[model_name][\"2.0\"][\"recall\"],\n",
    "            \"f1-score\": report_dict[model_name][\"macro avg\"][\"f1-score\"]\n",
    "        })\n",
    "        \n",
    "        mlflow.set_tag(\"Single Experiment/ Multiple Runs Training info\", f\"{model_name} model for wine\")\n",
    "        \n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "        \n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=f\"{model_name.lower()}_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"tracking-wine-{model_name.lower()}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        predictions = model.predict(X_test)\n",
    "        result = pd.DataFrame(X_test, columns=wine_feature_names).drop(columns=\"quality_label\")\n",
    "        result[\"actual_class\"] = y_test\n",
    "        result['predicted_class'] = predictions\n",
    "        result.to_csv(f\"{model_name}_predictions.csv\")\n",
    "        mlflow.log_artifact(f\"{model_name}_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d41c0",
   "metadata": {},
   "source": [
    "## Nested Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"MLflow_Wine_Nested\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Wine_Model_Comparison\"):\n",
    "    for model_name, model in models.items():\n",
    "        with mlflow.start_run(run_name=model_name, nested=True):\n",
    "            mlflow.log_params(params[model_name])\n",
    "            mlflow.log_metrics({\n",
    "                \"accuracy\": report_dict[model_name][\"accuracy\"],\n",
    "                \"recall_class_0\": report_dict[model_name][\"0.0\"][\"recall\"],\n",
    "                \"recall_class_1\": report_dict[model_name][\"1.0\"][\"recall\"],\n",
    "                \"recall_class_2\": report_dict[model_name][\"2.0\"][\"recall\"],\n",
    "                \"f1-score\": report_dict[model_name][\"macro avg\"][\"f1-score\"]\n",
    "            })\n",
    "            mlflow.set_tag(\"Training Info\", f\"{model_name} model for Wine\")\n",
    "            signature = infer_signature(X_train, model.predict(X_train))\n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                artifact_path=f\"{model_name.lower()}_model\",\n",
    "                signature=signature,\n",
    "                input_example=X_train,\n",
    "                registered_model_name=f\"tracking-wine-{model_name.lower()}\"\n",
    "            )\n",
    "            predictions = model.predict(X_test)\n",
    "            result = pd.DataFrame(X_test, columns=wine_feature_names).drop(columns=\"quality_label\", errors=\"ignore\")\n",
    "            result[\"actual_class\"] = y_test\n",
    "            result[\"predicted_class\"] = predictions\n",
    "            result.to_csv(f\"{model_name}_predictions.csv\")\n",
    "            mlflow.log_artifact(f\"{model_name}_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabff76",
   "metadata": {},
   "source": [
    "## Separate Experiments for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e880ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    mlflow.set_experiment(f\"MLflow_Wine_{model_name}\")\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_Run\"):\n",
    "        mlflow.log_params(params[model_name])\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": report_dict[model_name][\"accuracy\"],\n",
    "            \"recall_class_0\": report_dict[model_name][\"0.0\"][\"recall\"],\n",
    "            \"recall_class_1\": report_dict[model_name][\"1.0\"][\"recall\"],\n",
    "            \"recall_class_2\": report_dict[model_name][\"2.0\"][\"recall\"],\n",
    "            \"f1-score\": report_dict[model_name][\"macro avg\"][\"f1-score\"]\n",
    "        })\n",
    "        mlflow.set_tag(\"Training Info\", f\"{model_name} model for Wine\")\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=f\"{model_name.lower()}_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"tracking-wine-{model_name.lower()}\"\n",
    "        )\n",
    "        predictions = model.predict(X_test)\n",
    "        result = pd.DataFrame(X_test, columns=wine_feature_names).drop(columns=\"quality_label\", errors=\"ignore\")\n",
    "        result[\"actual_class\"] = y_test\n",
    "        result[\"predicted_class\"] = predictions\n",
    "        result.to_csv(f\"{model_name}_predictions.csv\")\n",
    "        mlflow.log_artifact(f\"{model_name}_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1e930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
